{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapted from https://www.kaggle.com/matleonard/intro-to-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing spaCy and loading English language Model\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing a line of text\n",
    "doc = nlp(\"Tea is healthy and calming, don't you think\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tea\n",
      "is\n",
      "healthy\n",
      "and\n",
      "calming\n",
      ",\n",
      "do\n",
      "n't\n",
      "you\n",
      "think\n"
     ]
    }
   ],
   "source": [
    "#Tokenization - splitting text into tokens\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice how don't is split into \"do\" and \"n't\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token \t\tLemma \t\tStopword\n",
      "----------------------------------------\n",
      "Tea\t\ttea\t\tFalse\n",
      "is\t\tbe\t\tTrue\n",
      "healthy\t\thealthy\t\tFalse\n",
      "and\t\tand\t\tTrue\n",
      "calming\t\tcalm\t\tFalse\n",
      ",\t\t,\t\tFalse\n",
      "do\t\tdo\t\tTrue\n",
      "n't\t\tnot\t\tTrue\n",
      "you\t\t-PRON-\t\tTrue\n",
      "think\t\tthink\t\tFalse\n"
     ]
    }
   ],
   "source": [
    "#Next step is Lemmatizing: Converting the tokens into root\n",
    "#and\n",
    "#Identifying Stopwords\n",
    "\n",
    "print('Token \\t\\tLemma \\t\\tStopword')\n",
    "print(\"-\"*40)\n",
    "for token in doc:\n",
    "    print(f\"{token}\\t\\t{token.lemma_}\\t\\t{token.is_stop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sometimes lemmatizing and removing stopwords can affect model performance, this should be kept in mind while hyperparameter optimization process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next lets look at Pattern Matching\n",
    "### Pattern matching is a common NLP task where tokens or phrases are searched for within a section or whole document. One can use regular expressions to achieve that, but spaCy offers a convenient way to do the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab, attr = 'LOWER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of terms to be matched.The phrase matcher needs the patterns as document objects.\n",
    "#The easiest way to get these is with a list comprehension using the nlp model.\n",
    "\n",
    "terms = ['Discovered', 'Tested', 'Hospital', 'Patients']\n",
    "patterns = [nlp(text) for text in terms]\n",
    "\n",
    "matcher.add(\"TerminologyList\", patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check datatype of patterns item\n",
    "type(patterns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed from https://en.wikipedia.org/wiki/Coronavirus\n",
    "\n",
    "text_doc= nlp('''The first reports of an infection caused, by what would later be determined to be a coronavirus, occurred in the late 1920s, when an acute respiratory infection of domesticated chickens emerged in North America.[15][16] Arthur Schalk and M.C. Hawn in 1931 made the first detailed report which described a new respiratory infection of chickens in North Dakota. The infection of new-born chicks was characterized by gasping and listlessness with high mortality rates of 40â€“90%.[17] Leland David Bushnell and Carl Alfred Brandly isolated the virus in 1933.[18] The virus was then known as infectious bronchitis virus (IBV). Charles D. Hudson and Fred Robert Beaudette cultivated the virus for the first time in 1937.[19] The specimen came to be known as the Beaudette strain. In the late 1940s, two more animal coronaviruses, JHM that caused brain disease (murine encephalitis) and mouse hepatitis virus (MHV) that caused hepatitis in mice were discovered.[20] It was not realized at the time that these three different viruses were related.[21]\n",
    "\n",
    "Human coronaviruses were discovered in the 1960s[22][23] using two different methods in the United Kingdom and the United States.[24] E.C. Kendall, Malcolm Bynoe, and David Tyrrell working at the Common Cold Unit of the British Medical Research Council collected a unique common cold virus designated B814 in 1961.[25][26][27] The virus could not be cultivated using standard techniques which had successfully cultivated rhinoviruses, adenoviruses and other known common cold viruses. In 1965, Tyrrell and Bynoe successfully cultivated the novel virus by serially passing it through organ culture of human embryonic trachea.[28] The new cultivating method was introduced to the lab by Bertil Hoorn.[29] The isolated virus when intranasally inoculated into volunteers caused a cold and was inactivated by ether which indicated it had a lipid envelope.[25][30] Dorothy Hamre[31] and John Procknow at the University of Chicago isolated a novel cold from medical students in 1962. They isolated and grew the virus in kidney tissue culture, assigning it as 229E. The novel virus caused a cold in volunteers and was inactivated by ether similarly as B814.[32]\n",
    "\n",
    "\n",
    "Transmission electron micrograph of organ cultured coronavirus OC43\n",
    "Scottish virologist June Almeida at St. Thomas Hospital in London, collaborating with Tyrrell, compared the structures of IBV, B814 and 229E in 1967.[33][34] Using electron microscopy the three viruses were shown to be morphologically related by their general shape and distinctive club-like spikes.[35] A research group at the National Institute of Health the same year was able to isolate another member of this new group of viruses using organ culture and named one of the samples OC43 (OC for organ culture).[36] Like B814, 229E, and IBV, the novel cold virus OC43 had distinctive club-like spikes when observed with the electron microscope.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3766102292120407359, 189, 190), (3766102292120407359, 392, 393)]\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(text_doc)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matches here are a tuple of the match id and the positions of the start and end of the phrase.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discovered\n",
      "Hospital\n"
     ]
    }
   ],
   "source": [
    "for match in matches:\n",
    "    _,start,end = match\n",
    "    print(text_doc[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It appears only two items were matched "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TerminologyList coronaviruses were discovered in the\n"
     ]
    }
   ],
   "source": [
    "match_id, start, end = matches[0]\n",
    "print(nlp.vocab.strings[match_id], text_doc[start-2:end+2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
